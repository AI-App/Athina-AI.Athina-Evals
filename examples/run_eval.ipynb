{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshat_g/ai_repos/athina-evals/athina-evals/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from athina.llms.openai_service import OpenAiService\n",
    "from athina.evals import DoesResponseAnswerQuery, ContextContainsEnoughInformation, Faithfulness, RagasContextRelevancy, RagasAnswerRelevancy\n",
    "from athina.evals import FunctionEvaluator\n",
    "from athina.loaders import RagLoader, ResponseLoader\n",
    "from athina.keys import AthinaApiKey, OpenAiApiKey\n",
    "from athina.interfaces.athina import AthinaFilters\n",
    "import pandas as pd\n",
    "from athina.llms.openai_service import OpenAiService\n",
    "\n",
    "OpenAiApiKey.set_key(os.getenv('OPENAI_API_KEY'))\n",
    "AthinaApiKey.set_key(os.getenv('ATHINA_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of Greece?</td>\n",
       "      <td>Greece is often called the cradle of Western c...</td>\n",
       "      <td>Athens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the price of a Tesla Model 3?</td>\n",
       "      <td>Tesla Model 3 is a fully electric car.</td>\n",
       "      <td>I cannot answer this question as prices vary f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a shooting star?</td>\n",
       "      <td>Black holes are stars that have collapsed unde...</td>\n",
       "      <td>A shooting star is a meteor that burns up in t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   query  \\\n",
       "0         What is the capital of Greece?   \n",
       "1  What is the price of a Tesla Model 3?   \n",
       "2               What is a shooting star?   \n",
       "\n",
       "                                             context  \\\n",
       "0  Greece is often called the cradle of Western c...   \n",
       "1             Tesla Model 3 is a fully electric car.   \n",
       "2  Black holes are stars that have collapsed unde...   \n",
       "\n",
       "                                            response  \n",
       "0                                             Athens  \n",
       "1  I cannot answer this question as prices vary f...  \n",
       "2  A shooting star is a meteor that burns up in t...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create batch dataset from list of dict objects\n",
    "raw_data_one = [\n",
    "    {\n",
    "        \"query\": \"What is the capital of Greece?\",\n",
    "        \"context\": \"Greece is often called the cradle of Western civilization.\",\n",
    "        \"response\": \"Athens\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the price of a Tesla Model 3?\",\n",
    "        \"context\": \"Tesla Model 3 is a fully electric car.\",\n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a shooting star?\",\n",
    "        \"context\": \"Black holes are stars that have collapsed under their own gravity. They are so dense that nothing can escape their gravitational pull, not even light.\",\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "dataset_one = RagLoader().load_dict(raw_data_one)\n",
    "pd.DataFrame(dataset_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [context_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>display_name</th>\n",
       "      <th>failed</th>\n",
       "      <th>grade_reason</th>\n",
       "      <th>runtime</th>\n",
       "      <th>model</th>\n",
       "      <th>ragas_context_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the capital of Greece?</td>\n",
       "      <td>Greece is often called the cradle of Western civilization.</td>\n",
       "      <td>Athens</td>\n",
       "      <td>Context Relevancy</td>\n",
       "      <td>None</td>\n",
       "      <td>This metric is calulated by dividing the number of sentences in context that are relevant for answering the given query by the total number of sentences in the retrieved context</td>\n",
       "      <td>1792</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the price of a Tesla Model 3?</td>\n",
       "      <td>Tesla Model 3 is a fully electric car.</td>\n",
       "      <td>I cannot answer this question as prices vary from country to country.</td>\n",
       "      <td>Context Relevancy</td>\n",
       "      <td>None</td>\n",
       "      <td>This metric is calulated by dividing the number of sentences in context that are relevant for answering the given query by the total number of sentences in the retrieved context</td>\n",
       "      <td>1317</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is a shooting star?</td>\n",
       "      <td>Black holes are stars that have collapsed under their own gravity. They are so dense that nothing can escape their gravitational pull, not even light.</td>\n",
       "      <td>A shooting star is a meteor that burns up in the atmosphere.</td>\n",
       "      <td>Context Relevancy</td>\n",
       "      <td>None</td>\n",
       "      <td>This metric is calulated by dividing the number of sentences in context that are relevant for answering the given query by the total number of sentences in the retrieved context</td>\n",
       "      <td>844</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   query  \\\n",
       "0         What is the capital of Greece?   \n",
       "1  What is the price of a Tesla Model 3?   \n",
       "2               What is a shooting star?   \n",
       "\n",
       "                                                                                                                                                  context  \\\n",
       "0                                                                                              Greece is often called the cradle of Western civilization.   \n",
       "1                                                                                                                  Tesla Model 3 is a fully electric car.   \n",
       "2  Black holes are stars that have collapsed under their own gravity. They are so dense that nothing can escape their gravitational pull, not even light.   \n",
       "\n",
       "                                                                response  \\\n",
       "0                                                                 Athens   \n",
       "1  I cannot answer this question as prices vary from country to country.   \n",
       "2           A shooting star is a meteor that burns up in the atmosphere.   \n",
       "\n",
       "        display_name failed  \\\n",
       "0  Context Relevancy   None   \n",
       "1  Context Relevancy   None   \n",
       "2  Context Relevancy   None   \n",
       "\n",
       "                                                                                                                                                                        grade_reason  \\\n",
       "0  This metric is calulated by dividing the number of sentences in context that are relevant for answering the given query by the total number of sentences in the retrieved context   \n",
       "1  This metric is calulated by dividing the number of sentences in context that are relevant for answering the given query by the total number of sentences in the retrieved context   \n",
       "2  This metric is calulated by dividing the number of sentences in context that are relevant for answering the given query by the total number of sentences in the retrieved context   \n",
       "\n",
       "   runtime          model  ragas_context_relevancy  \n",
       "0     1792  gpt-3.5-turbo                      0.0  \n",
       "1     1317  gpt-3.5-turbo                      0.0  \n",
       "2      844  gpt-3.5-turbo                      0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRelevancy(model=eval_model).run_batch(data=dataset_one).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is France and what is it's capital?</td>\n",
       "      <td>France is the country in europe known for delicious cuisine. Paris is the capital of france</td>\n",
       "      <td>Tesla is an electric car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is France and what is it's capital?</td>\n",
       "      <td>France is the country in europe known for delicious cuisine. Paris is the capital of france</td>\n",
       "      <td>France is in western Europe and Paris is its capital</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       query  \\\n",
       "0  Where is France and what is it's capital?   \n",
       "1  Where is France and what is it's capital?   \n",
       "\n",
       "                                                                                       context  \\\n",
       "0  France is the country in europe known for delicious cuisine. Paris is the capital of france   \n",
       "1  France is the country in europe known for delicious cuisine. Paris is the capital of france   \n",
       "\n",
       "                                               response  \n",
       "0                              Tesla is an electric car  \n",
       "1  France is in western Europe and Paris is its capital  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_two = [\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"context\": \"France is the country in europe known for delicious cuisine. Paris is the capital of france\",\n",
    "        \"response\": \"Tesla is an electric car\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"context\": \"France is the country in europe known for delicious cuisine. Paris is the capital of france\",\n",
    "        \"response\": \"France is in western Europe and Paris is its capital\",\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_two = RagLoader().load_dict(raw_data_two)\n",
    "pd.DataFrame(dataset_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating with [answer_relevancy]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>display_name</th>\n",
       "      <th>failed</th>\n",
       "      <th>grade_reason</th>\n",
       "      <th>runtime</th>\n",
       "      <th>model</th>\n",
       "      <th>ragas_answer_relevancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is France and what is it's capital?</td>\n",
       "      <td>France is the country in europe known for delicious cuisine. Paris is the capital of france</td>\n",
       "      <td>Tesla is an electric car</td>\n",
       "      <td>Answer Relevancy</td>\n",
       "      <td>None</td>\n",
       "      <td>A response is deemed relevant when it directly and appropriately addresses the original query. Importantly, our assessment of answer relevance does not consider factuality but instead penalizes cases where the response lacks completeness or contains redundant details</td>\n",
       "      <td>3168</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.749017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is France and what is it's capital?</td>\n",
       "      <td>France is the country in europe known for delicious cuisine. Paris is the capital of france</td>\n",
       "      <td>France is in western Europe and Paris is its capital</td>\n",
       "      <td>Answer Relevancy</td>\n",
       "      <td>None</td>\n",
       "      <td>A response is deemed relevant when it directly and appropriately addresses the original query. Importantly, our assessment of answer relevance does not consider factuality but instead penalizes cases where the response lacks completeness or contains redundant details</td>\n",
       "      <td>2473</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>0.975475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       query  \\\n",
       "0  Where is France and what is it's capital?   \n",
       "1  Where is France and what is it's capital?   \n",
       "\n",
       "                                                                                       context  \\\n",
       "0  France is the country in europe known for delicious cuisine. Paris is the capital of france   \n",
       "1  France is the country in europe known for delicious cuisine. Paris is the capital of france   \n",
       "\n",
       "                                               response      display_name  \\\n",
       "0                              Tesla is an electric car  Answer Relevancy   \n",
       "1  France is in western Europe and Paris is its capital  Answer Relevancy   \n",
       "\n",
       "  failed  \\\n",
       "0   None   \n",
       "1   None   \n",
       "\n",
       "                                                                                                                                                                                                                                                                  grade_reason  \\\n",
       "0  A response is deemed relevant when it directly and appropriately addresses the original query. Importantly, our assessment of answer relevance does not consider factuality but instead penalizes cases where the response lacks completeness or contains redundant details   \n",
       "1  A response is deemed relevant when it directly and appropriately addresses the original query. Importantly, our assessment of answer relevance does not consider factuality but instead penalizes cases where the response lacks completeness or contains redundant details   \n",
       "\n",
       "   runtime          model  ragas_answer_relevancy  \n",
       "0     3168  gpt-3.5-turbo                0.749017  \n",
       "1     2473  gpt-3.5-turbo                0.975475  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run_batch(data=dataset_two).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "ContextContainsEnoughInformation(model=eval_model).run_batch(data=dataset_one).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the LLM response answers the user query sufficiently\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "DoesResponseAnswerQuery(model=eval_model).run_batch(data=dataset_one).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the LLM response is faithful to the information provided to it\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "data = {\n",
    "        \"query\": \"What is the capital of Greece?\",\n",
    "        \"context\": [\"Greece is often called the cradle of Western civilization.\", \"Greece is the ancient birthplace of the Olympic Games.\"],\n",
    "        \"response\": \"Athens\",\n",
    "    }\n",
    "Faithfulness(model=eval_model).run(**data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the context contains enough information to answer the user query provided\n",
    "eval_model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom evaluator\n",
    "# Checks if the response mentions black holes\n",
    "grading_criteria=\"If the response mentions black holes, then fail. Otherwise pass.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = [\n",
    "    {\n",
    "        \"query\": \"What is the capital of Greece?\",\n",
    "        \"context\": [\"Greece is often called the cradle of Western civilization.\", \"Greece is the ancient birthplace of the Olympic Games.\"],\n",
    "        \"response\": \"Athens\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the price of a Tesla Model 3?\",\n",
    "        \"context\": [\"Tesla Model 3 is a fully electric car.\"],\n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a shooting star?\",\n",
    "        \"context\": [\"Black holes are stars that have collapsed under their own gravity. They are so dense that nothing can escape their gravitational pull, not even light.\"],\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "functionEvaluator = FunctionEvaluator(function_name=\"ContainsAny\", function_arguments={\n",
    "    \"keywords\": [\"tesla\", \"animal\", \"star\"]\n",
    "})\n",
    "functionEvaluator.run_batch(data=dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can run our function based evaluators as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from athina.evals import ContainsAny, Regex\n",
    "from athina.loaders import ResponseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response contains any of the keywords\n",
    "ContainsAny(keywords=[\"star\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"Contact us at hello@athina.ai to get access to our LLM observability platform where you can run the tests you've defined here against your LLM responses in production.\",\n",
    "    }\n",
    "]\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response matches the regex\n",
    "Regex(regex='([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)').run_batch(data=dataset).to_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
