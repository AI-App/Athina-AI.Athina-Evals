{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshat_g/ai_repos/athina-evals/athina-evals/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from athina.llms.openai_service import OpenAiService\n",
    "from athina.evals import (\n",
    "    DoesResponseAnswerQuery,\n",
    "    ContextContainsEnoughInformation,\n",
    "    Faithfulness,\n",
    "    RagasContextRelevancy,\n",
    "    RagasAnswerRelevancy,\n",
    "    RagasContextPrecision,\n",
    "    RagasFaithfulness,\n",
    "    RagasContextRecall,\n",
    "    RagasAnswerSemanticSimilarity,\n",
    "    RagasAnswerCorrectness,\n",
    "    RagasHarmfulness,\n",
    "    RagasMaliciousness,\n",
    "    RagasCoherence,\n",
    "    RagasConciseness\n",
    ")\n",
    "\n",
    "from athina.evals import FunctionEvaluator\n",
    "from athina.loaders import Loader\n",
    "from athina.keys import AthinaApiKey, OpenAiApiKey\n",
    "from athina.interfaces.athina import AthinaFilters\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OpenAiApiKey.set_key(os.getenv('OPENAI_API_KEY'))\n",
    "AthinaApiKey.set_key(os.getenv('ATHINA_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>expected_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is France and what is it's capital?</td>\n",
       "      <td>[France is the country in europe known for del...</td>\n",
       "      <td>Tesla is an electric car</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where is France and what is it's capital?</td>\n",
       "      <td>[France is the country in europe known for del...</td>\n",
       "      <td>France is in western Europe and Paris is its c...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       query  \\\n",
       "0  Where is France and what is it's capital?   \n",
       "1  Where is France and what is it's capital?   \n",
       "\n",
       "                                             context  \\\n",
       "0  [France is the country in europe known for del...   \n",
       "1  [France is the country in europe known for del...   \n",
       "\n",
       "                                            response expected_response  \n",
       "0                           Tesla is an electric car              None  \n",
       "1  France is in western Europe and Paris is its c...              None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = [\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"context\": [\"France is the country in europe known for delicious cuisine\", \"Tesla is an electric car\", \"Elephant is an animal\"],\n",
    "        \"response\": \"Tesla is an electric car\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"context\": [\"France is the country in europe known for delicious cuisine\", \"Paris is the capital of france\"],\n",
    "        \"response\": \"France is in western Europe and Paris is its capital\",\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_raw_data = Loader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset_raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while creating eval request AuthorizationError (Extra Info: please check your athina api key and try again)\n",
      "An error occurred while creating eval request AuthorizationError (Extra Info: please check your athina api key and try again)\n"
     ]
    },
    {
     "ename": "CustomException",
     "evalue": "AuthorizationError (Extra Info: please check your athina api key and try again)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m eval_model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m RagasAnswerRelevancy(model\u001b[39m=\u001b[39;49meval_model)\u001b[39m.\u001b[39;49mrun_batch(data\u001b[39m=\u001b[39;49mdataset_raw_data)\u001b[39m.\u001b[39mto_df()\n",
      "File \u001b[0;32m~/ai_repos/athina-evals/athina-evals/athina/evals/base_evaluator.py:153\u001b[0m, in \u001b[0;36mBaseEvaluator.run_batch\u001b[0;34m(self, data, max_parallel_evals)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mRuns the evaluator on a batch of data.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# Create eval request\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m eval_request_id \u001b[39m=\u001b[39m AthinaLoggingHelper\u001b[39m.\u001b[39;49mcreate_eval_request(\n\u001b[1;32m    154\u001b[0m     eval_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, request_data\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data}, request_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbatch\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    155\u001b[0m )\n\u001b[1;32m    157\u001b[0m \u001b[39m# Log usage to Athina for analytics\u001b[39;00m\n\u001b[1;32m    158\u001b[0m AthinaApiService\u001b[39m.\u001b[39mlog_usage(eval_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, run_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ai_repos/athina-evals/athina-evals/athina/helpers/athina_logging_helper.py:45\u001b[0m, in \u001b[0;36mAthinaLoggingHelper.create_eval_request\u001b[0;34m(eval_name, request_data, request_type)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39m# Create eval request\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     eval_request \u001b[39m=\u001b[39m AthinaEvalRequestCreateRequest(\n\u001b[1;32m     40\u001b[0m         request_label\u001b[39m=\u001b[39meval_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_eval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(time\u001b[39m.\u001b[39mtime()),\n\u001b[1;32m     41\u001b[0m         request_data\u001b[39m=\u001b[39mrequest_data,\n\u001b[1;32m     42\u001b[0m         request_data_type\u001b[39m=\u001b[39mrequest_type,\n\u001b[1;32m     43\u001b[0m         source\u001b[39m=\u001b[39mAthinaEvalRequestSource\u001b[39m.\u001b[39mDEV_SDK\u001b[39m.\u001b[39mvalue,\n\u001b[1;32m     44\u001b[0m     )\n\u001b[0;32m---> 45\u001b[0m     eval_request_id \u001b[39m=\u001b[39m AthinaApiService\u001b[39m.\u001b[39;49mcreate_eval_request(eval_request)[\n\u001b[1;32m     46\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m     ][\u001b[39m\"\u001b[39m\u001b[39meval_request\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     48\u001b[0m     \u001b[39mreturn\u001b[39;00m eval_request_id\n\u001b[1;32m     49\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/ai_repos/athina-evals/athina-evals/athina/services/athina_api_service.py:141\u001b[0m, in \u001b[0;36mAthinaApiService.create_eval_request\u001b[0;34m(athina_eval_request_create_request)\u001b[0m\n\u001b[1;32m    139\u001b[0m     error_message \u001b[39m=\u001b[39m response_json\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUnknown Error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    140\u001b[0m     details_message \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplease check your athina api key and try again\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 141\u001b[0m     \u001b[39mraise\u001b[39;00m CustomException(error_message, details_message)\n\u001b[1;32m    142\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    143\u001b[0m     response_json \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()\n",
      "\u001b[0;31mCustomException\u001b[0m: AuthorizationError (Extra Info: please check your athina api key and try again)"
     ]
    }
   ],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run_batch(data=dataset_raw_data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"contexts\": [\"France is the country in europe known for delicious cuisine\", \"Tesla is an electric car\", \"Elephant is an animal\"],\n",
    "        \"response\": \"Tesla is an electric car\",\n",
    "    }\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run(**data).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ragas_with_expected_response = [\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"contexts\": [\"France is the country in europe known for delicious cuisine\", \"Tesla is an electric car\", \"Elephant is an animal\"],\n",
    "        \"response\": \"Tesla is an electric car\",\n",
    "        \"expected_response\": \"France is in europe. Paris is it's capital\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is Tesla? Who founded it?\",\n",
    "        \"contexts\": [\"Tesla is the electric car company. Tesla is registerd in United States\", \"Elon Musk founded it\"],\n",
    "        \"response\": \"France is in western Europe and Paris is its capital\",\n",
    "        \"expected_response\": \"Tesla is an electric car company. Elon Musk founded it.\"\n",
    "    },\n",
    "]\n",
    "dataset_raw_data_ragas_with_expected_response = RagasLoader().load_dict(raw_data_ragas_with_expected_response)\n",
    "pd.DataFrame(dataset_raw_data_ragas_with_expected_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextPrecision(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRelevancy(model=eval_model).run_batch(data=dataset_raw_data_ragas).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasFaithfulness(model=eval_model).run_batch(data=dataset_raw_data_ragas).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRecall(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerSemanticSimilarity(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerCorrectness(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasHarmfulness(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasMaliciousness(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasCoherence(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasConciseness(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch dataset from list of dict objects\n",
    "raw_data = [\n",
    "    {\n",
    "        \"query\": \"What is the capital of Greece?\",\n",
    "        \"context\": [\"Greece is often called the cradle of Western civilization.\"],\n",
    "        \"response\": \"Athens\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the price of a Tesla Model 3?\",\n",
    "        \"context\": [\"Tesla Model 3 is a fully electric car.\"],\n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a shooting star?\",\n",
    "        \"context\": [\"Black holes are stars that have collapsed under their own gravity. They are so dense that nothing can escape their gravitational pull, not even light.\"],\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "dataset = Loader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Loader().load_athina_inferences(limit=5)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Loader().load_athina_inferences(limit=5)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "ContextContainsEnoughInformation(model=eval_model).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the LLM response answers the user query sufficiently\n",
    "eval_model = \"gpt-4\"\n",
    "DoesResponseAnswerQuery(model=eval_model).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the LLM response is faithful to the information provided to it\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "Faithfulness(model=eval_model).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can run our function based evaluators as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from athina.evals import ContainsAny, Regex\n",
    "from athina.loaders import ResponseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response contains any of the keywords\n",
    "ContainsAny(keywords=[\"star\"]).run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"Contact us at hello@athina.ai to get access to our LLM observability platform where you can run the tests you've defined here against your LLM responses in production.\",\n",
    "    }\n",
    "]\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response matches the regex\n",
    "Regex(regex='([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)').run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsNone\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\n",
    "        \"response\": \"This text does not contain the specified keyword.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"This is a text without any specified search word.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsNone(keywords=[\"keyword\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import Contains\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\n",
    "        \"response\": \"The keyword YC present in this text.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"This text does not contain the specified word.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "Contains(keyword=\"YC\").run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsAll\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"This text contains both keyword1 and keyword2.\"},\n",
    "    {\"response\": \"This text does not contain all specified keywords.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsAll(keywords=[\"keyword1\", \"keyword2\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsJson\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": '{\"key\": \"value\"}'},\n",
    "    {\"response\": '{\"invalid : \"json\"}'},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsJson().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsEmail\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Contact us at contact@example.com.\"},\n",
    "    {\"response\": \"This text does not contain any email address.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsEmail().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import IsJson\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": '{\"key\": \"value\"}'},\n",
    "    {\"response\": 'invalid_json'},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "IsJson().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import IsEmail\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"john.doe@example.com\"},\n",
    "    {\"response\": \"invalid.email\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "IsEmail().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsLink\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"For more information, visit https://example.com.\"},\n",
    "    {\"response\": \"This text does not contain any link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsLink().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ContainsValidLink\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Visit our official website at http://example.com.\"},\n",
    "    {\"response\": \"Visit our official website at https://exampleasdf.com\"},\n",
    "    {\"response\": \"This text does not contain any valid link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ContainsValidLink().run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import NoInvalidLinks\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Visit our website at https://example.com.\"},\n",
    "    {\"response\": \"Visit our official website at https://exampleasdf.com\"},\n",
    "    {\"response\": \"This text does not contain any valid link.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "\n",
    "# Example calls\n",
    "NoInvalidLinks().run_batch(data=dataset).to_df()\n",
    "NoInvalidLinks().run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import ApiCall\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Response to be sent to the your own API based evaluator\"}\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "ApiCall(url=\"https://8e714940905f4022b43267e348b8a71.api.mockbin.io/\", payload={\"evaluator\": \"custom_api_based_evaluator\"}, headers={\"Authorization\": \"Bearer token\"}).run_batch(data=dataset).to_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import Equals\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"This is the expected response\"},\n",
    "    {\"response\": \"This is an unexpected response\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "Equals(expected_response=\"This is the expected response\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import StartsWith\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"The text starts with this substring.\"},\n",
    "    {\"response\": \"This text does not start with the specified substring.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "StartsWith(substring=\"The text starts with\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import EndsWith\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"The text ends with this substring.\"},\n",
    "    {\"response\": \"This text does not end with the specified substring.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "EndsWith(substring=\"with this substring.\").run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import LengthLessThan\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Short text\"},\n",
    "    {\"response\": \"This is a longer text.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "LengthLessThan(max_length=20).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from athina.evals import LengthGreaterThan\n",
    "\n",
    "# Example data\n",
    "raw_data = [\n",
    "    {\"response\": \"Short text\"},\n",
    "    {\"response\": \"This is a longer text.\"},\n",
    "]\n",
    "\n",
    "# Load data into dataset\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "LengthGreaterThan(min_length=20).run_batch(data=dataset).to_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
