{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from athina.llms.openai_service import OpenAiService\n",
    "from athina.evals import DoesResponseAnswerQuery, ContextContainsEnoughInformation, Faithfulness, RagasContextRelevancy, RagasAnswerRelevancy, RagasContextPrecision, RagasFaithfulness, RagasContextRecall, RagasAnswerSemanticSimilarity\n",
    "from athina.evals import FunctionEvaluator\n",
    "from athina.loaders import RagLoader, ResponseLoader, RagasLoader\n",
    "from athina.keys import AthinaApiKey, OpenAiApiKey\n",
    "from athina.interfaces.athina import AthinaFilters\n",
    "import pandas as pd\n",
    "from athina.llms.openai_service import OpenAiService\n",
    "\n",
    "OpenAiApiKey.set_key(os.getenv('OPENAI_API_KEY'))\n",
    "AthinaApiKey.set_key(os.getenv('ATHINA_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ragas = [\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"contexts\": [\"France is the country in europe known for delicious cuisine\", \"Tesla is an electric car\", \"Elephant is an animal\"],\n",
    "        \"response\": \"Tesla is an electric car\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"contexts\": [\"France is the country in europe known for delicious cuisine\", \"Paris is the capital of france\"],\n",
    "        \"response\": \"France is in western Europe and Paris is its capital\",\n",
    "    },\n",
    "]\n",
    "\n",
    "dataset_raw_data_ragas = RagasLoader().load_dict(raw_data_ragas)\n",
    "pd.DataFrame(dataset_raw_data_ragas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerRelevancy(model=eval_model).run_batch(data=dataset_raw_data_ragas).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_ragas_with_expected_response = [\n",
    "    {\n",
    "        \"query\": \"Where is France and what is it's capital?\",\n",
    "        \"contexts\": [\"France is the country in europe known for delicious cuisine\", \"Tesla is an electric car\", \"Elephant is an animal\"],\n",
    "        \"response\": \"Tesla is an electric car\",\n",
    "        \"expected_response\": \"France is in europe. Paris is it's capital\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is Tesla? Who founded it?\",\n",
    "        \"contexts\": [\"Tesla is the electric car company. Tesla is registerd in United States\", \"Elon Musk founded it\"],\n",
    "        \"response\": \"France is in western Europe and Paris is its capital\",\n",
    "        \"expected_response\": \"Tesla is an electric car company. Elon Musk founded it.\"\n",
    "    },\n",
    "]\n",
    "dataset_raw_data_ragas_with_expected_response = RagasLoader().load_dict(raw_data_ragas_with_expected_response)\n",
    "pd.DataFrame(dataset_raw_data_ragas_with_expected_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextPrecision(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRelevancy(model=eval_model).run_batch(data=dataset_raw_data_ragas).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasFaithfulness(model=eval_model).run_batch(data=dataset_raw_data_ragas).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasContextRecall(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "RagasAnswerSemanticSimilarity(model=eval_model).run_batch(data=dataset_raw_data_ragas_with_expected_response).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batch dataset from list of dict objects\n",
    "raw_data_two = [\n",
    "    {\n",
    "        \"query\": \"What is the capital of Greece?\",\n",
    "        \"context\": \"Greece is often called the cradle of Western civilization.\",\n",
    "        \"response\": \"Athens\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is the price of a Tesla Model 3?\",\n",
    "        \"context\": \"Tesla Model 3 is a fully electric car.\",\n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a shooting star?\",\n",
    "        \"context\": \"Black holes are stars that have collapsed under their own gravity. They are so dense that nothing can escape their gravitational pull, not even light.\",\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "\n",
    "dataset_one = RagLoader().load_dict(raw_data_one)\n",
    "pd.DataFrame(dataset_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = \"gpt-3.5-turbo\"\n",
    "ContextContainsEnoughInformation(model=eval_model).run_batch(data=dataset_one).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the LLM response answers the user query sufficiently\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "DoesResponseAnswerQuery(model=eval_model).run_batch(data=dataset_one).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if the LLM response is faithful to the information provided to it\n",
    "eval_model = \"gpt-3.5-turbo\"\n",
    "Faithfulness(model=eval_model).run_batch(data=dataset_one).to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can run our function based evaluators as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from athina.evals import ContainsAny, Regex\n",
    "from athina.loaders import ResponseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"A shooting star is a meteor that burns up in the atmosphere.\",\n",
    "    }\n",
    "]\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response contains any of the keywords\n",
    "ContainsAny(keywords=[\"star\"]).run_batch(data=dataset).to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "raw_data = [ \n",
    "    { \n",
    "        \"response\": \"I cannot answer this question as prices vary from country to country.\",\n",
    "    },\n",
    "    {\n",
    "        \"response\": \"Contact us at hello@athina.ai to get access to our LLM observability platform where you can run the tests you've defined here against your LLM responses in production.\",\n",
    "    }\n",
    "]\n",
    "dataset = ResponseLoader().load_dict(raw_data)\n",
    "pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval checks if the response matches the regex\n",
    "Regex(regex='([a-zA-Z0-9._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)').run_batch(data=dataset).to_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
