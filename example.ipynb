{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from athina.llms.openai_service import OpenAiService\n",
    "from athina.evals import AnswerRelevance, ContextRelevance, Faithfulness\n",
    "# from athina.evals import AnswerRelevance\n",
    "from athina.keys import AthinaApiKey, OpenAiApiKey\n",
    "\n",
    "OpenAiApiKey.set_key(os.getenv('OPENAI_API_KEY'))\n",
    "AthinaApiKey.set_key(os.getenv('ATHINA_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your inference call to OpenAI\n",
    "model = \"gpt-3.5-turbo\"\n",
    "user_query = \"Who is the president of the United States?\"\n",
    "context = \"The year is 2023. The president is Shiv Sakhuja.\"\n",
    "prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Use the information provided to you to answer the user's question. Information: {context}\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_query\n",
    "    }\n",
    "]\n",
    "\n",
    "openai_service = OpenAiService()\n",
    "response = openai_service.chat_completion(prompt, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'failure': True,\n",
       " 'reason': \"The response does not answer the user's query sufficiently because it does not mention the name of the president.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the answer relevance evaluator\n",
    "# Checks if the LLM response answers the user query sufficiently\n",
    "AnswerRelevance(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ").run(user_query=user_query, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'failure': True,\n",
       " 'reason': 'The response cannot be inferred from the provided context. The context only mentions the year and the name of the president, but it does not provide any information about the president of the United States in 2023. Therefore, we cannot infer that Shiv Sakhuja is the president of the United States in 2023 based solely on the given context.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the faithfulness evaluator\n",
    "# Checks if the LLM response is faithful to the information provided to it\n",
    "Faithfulness(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ").run(context=context, response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'failure': True,\n",
       " 'reason': \"The response does not contain enough information to answer the user's query. The response does not mention the name of the president.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the context relevance evaluator\n",
    "# Checks if the context is relevant to the user query\n",
    "ContextRelevance(\n",
    "    model=\"gpt-3.5-turbo\"\n",
    ").run(context=context, user_query=user_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
